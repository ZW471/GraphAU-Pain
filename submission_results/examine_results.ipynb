{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T20:16:40.482463Z",
     "start_time": "2025-01-07T20:16:39.099192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def process_multiple_inputs(input_file_output_folder_pairs, cate_num=3):\n",
    "    \"\"\"\n",
    "    Processes multiple input file pairs, computes the classification report and confusion matrix,\n",
    "    and saves the outputs (confusion matrix image and classification report CSV) to the respective output folders.\n",
    "\n",
    "    Args:\n",
    "        input_file_output_folder_pairs (list of tuples): A list where each tuple contains:\n",
    "            - First element: List of two file paths [predictions_file, labels_file].\n",
    "            - Second element: Output folder path for saving results.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Define the column headers and label mapping\n",
    "    if cate_num == 3:\n",
    "        columns = ['Mild Pain', 'No Pain', 'Pain']\n",
    "        label_mapping = {0: 'No Pain', 1: 'Mild', 2: 'Obvious'}\n",
    "    elif cate_num == 4:\n",
    "        columns = ['Mild Pain', 'No Pain', 'Pain', 'Obvious']\n",
    "        label_mapping = {0: 'No Pain', 1: 'Weak', 2: 'Mild', 3: 'Strong'}\n",
    "\n",
    "    for file_pair in input_file_output_folder_pairs:\n",
    "        # Unpack each tuple\n",
    "        input_files, output_folder = file_pair\n",
    "        predictions_file = input_files[0]\n",
    "        labels_file = input_files[1]\n",
    "\n",
    "        # Ensure the output folder exists\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Read and process labels\n",
    "        with open(labels_file, 'r') as lab:\n",
    "            labels = lab.readlines()\n",
    "            labels = [x.strip() for x in labels]\n",
    "            labels = [x.split(' ') for x in labels]\n",
    "            labels = pd.DataFrame(labels, columns=columns)\n",
    "            labels = labels.astype(int).idxmax(axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "        # Read and process predictions\n",
    "        with open(predictions_file, 'r') as pred:\n",
    "            predictions = pred.readlines()\n",
    "            predictions = [x.strip() for x in predictions]\n",
    "            predictions = [x.split(' ') for x in predictions]\n",
    "            predictions = pd.DataFrame(predictions, columns=columns)\n",
    "            predictions = predictions.astype(int).idxmax(axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "        # Generate and save classification report\n",
    "        report = classification_report(labels, predictions, target_names=label_mapping.values(), output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        report_csv_path = os.path.join(output_folder, 'classification_report.csv')\n",
    "        report_df.to_csv(report_csv_path)\n",
    "        print(f\"Classification report saved at: {report_csv_path}\")\n",
    "\n",
    "        # Generate and save confusion matrix\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        cm_original = cm.copy()  # Keep a copy of the original amounts\n",
    "        cm += 1\n",
    "        cm = np.log10(cm)\n",
    "\n",
    "        plt.figure(figsize=(7, 6))\n",
    "        ax = sns.heatmap(cm, annot=True, fmt='.2f', cmap=sns.light_palette(\"seagreen\", as_cmap=True),\n",
    "                         xticklabels=label_mapping.values(), yticklabels=label_mapping.values(), annot_kws={\"size\": 20},\n",
    "                         square=True, vmin=0, vmax=4, cbar=False)\n",
    "\n",
    "        # Add original amounts under the heatmap annotations (slightly lower and with white background)\n",
    "        for i in range(cm_original.shape[0]):\n",
    "            for j in range(cm_original.shape[1]):\n",
    "                text = ax.text(j + 0.5, i + 0.7, f\"({cm_original[i, j]})\",\n",
    "                               fontsize=14, color=\"black\", ha='center', va='center', clip_on=True,\n",
    "                               bbox=dict(boxstyle=\"round,pad=0.2\", edgecolor='none', facecolor='white', alpha=0.8))\n",
    "\n",
    "        # Customizing visualization\n",
    "        plt.xlabel(\"Predicted\", fontsize=20, fontweight='bold')\n",
    "        plt.ylabel(\"Actual\", fontsize=20, fontweight='bold')\n",
    "        plt.xticks(fontsize=18)  # Set x-ticklabel font size\n",
    "        plt.yticks(fontsize=18)  # Set y-ticklabel font size\n",
    "        # No title\n",
    "        confusion_matrix_path = os.path.join(output_folder, 'confusion_matrix.png')\n",
    "        plt.savefig(confusion_matrix_path, bbox_inches='tight', pad_inches=0.1)\n",
    "        plt.close()  # Close the plot to avoid memory issues\n",
    "        print(f\"Confusion matrix saved at: {confusion_matrix_path}\")\n",
    "\n",
    "# Example list of input file pairs\n",
    "input_file_output_folder_pairs = [\n",
    "    (['bb.txt', '../data/UNBC/list/UNBC_test_pspi_fold1.txt'], 'only backbone'),\n",
    "    (['no gnn.txt', '../data/UNBC/list/UNBC_test_pspi_fold1.txt'], 'no gnn'),\n",
    "    (['pain_predictions.txt', '../data/UNBC/list/UNBC_test_pspi_fold1.txt'], 'full'),\n",
    "    (['full gr.txt', '../data/UNBC/list/UNBC_test_pspi_fold1.txt'], 'full + graph representation'),\n",
    "    (['full gr no sft.txt', '../data/UNBC/list/UNBC_test_pspi_fold1.txt'], 'full no sft'),\n",
    "]\n",
    "\n",
    "# Call the function\n",
    "process_multiple_inputs(input_file_output_folder_pairs)\n",
    "\n",
    "process_multiple_inputs(\n",
    "    [(['4cat.txt', '../data/UNBC/list/final_4/UNBC_test_pspi_fold1.txt'], '4 cat')], cate_num=4\n",
    ")"
   ],
   "id": "3cb6ea07d8c52456",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report saved at: only backbone\\classification_report.csv\n",
      "Confusion matrix saved at: only backbone\\confusion_matrix.png\n",
      "Classification report saved at: no gnn\\classification_report.csv\n",
      "Confusion matrix saved at: no gnn\\confusion_matrix.png\n",
      "Classification report saved at: full\\classification_report.csv\n",
      "Confusion matrix saved at: full\\confusion_matrix.png\n",
      "Classification report saved at: full + graph representation\\classification_report.csv\n",
      "Confusion matrix saved at: full + graph representation\\confusion_matrix.png\n",
      "Classification report saved at: full no sft\\classification_report.csv\n",
      "Confusion matrix saved at: full no sft\\confusion_matrix.png\n",
      "Classification report saved at: 4 cat\\classification_report.csv\n",
      "Confusion matrix saved at: 4 cat\\confusion_matrix.png\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T20:22:46.336960Z",
     "start_time": "2025-01-07T20:22:46.310471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Folder names and abbreviated model names\n",
    "folders = {'full + graph representation': 'Full', 'full': 'W/o graph rep.', 'no gnn': 'W/o GNN','only backbone': 'Only ResNet' }\n",
    "categories = ['No Pain', 'Mild', 'Obvious']\n",
    "# Initialize an empty dictionary to store the metrics\n",
    "model_metrics = {}\n",
    "\n",
    "# Loop through each folder to extract required metrics (F1-score, recall, and precision)\n",
    "for folder, abbrev in folders.items():\n",
    "    report_path = os.path.join(folder, 'classification_report.csv')\n",
    "    if os.path.exists(report_path):\n",
    "        report = pd.read_csv(report_path, index_col=0)\n",
    "\n",
    "        # Get F1-scores, recall, and precision for each class\n",
    "        f1_scores = report.loc[['No Pain', 'Mild', 'Obvious'], 'f1-score'].values\n",
    "        recalls = report.loc[['No Pain', 'Mild', 'Obvious'], 'recall'].values\n",
    "        precisions = report.loc[['No Pain', 'Mild', 'Obvious'], 'precision'].values\n",
    "\n",
    "        # Save F1, recall, and precision for the current model\n",
    "        model_metrics[abbrev] = {'f1': f1_scores, 'recall': recalls, 'precision': precisions}\n",
    "\n",
    "# Calculate min and max for each category across all metrics\n",
    "min_max_values = {}\n",
    "for metric in ['f1', 'recall', 'precision']:\n",
    "    min_max_values[metric] = {i: (float('inf'), float('-inf')) for i in range(len(categories))}\n",
    "\n",
    "for model in model_metrics.values():\n",
    "    for metric in min_max_values.keys():\n",
    "        for i, value in enumerate(model[metric]):\n",
    "            current_min, current_max = min_max_values[metric][i]\n",
    "            min_max_values[metric][i] = (min(current_min, value), max(current_max, value))\n",
    "\n",
    "# Calculate min and max values for the mean column\n",
    "mean_min, mean_max = float('inf'), float('-inf')\n",
    "\n",
    "# Compute min and max for the mean column across all models\n",
    "for model in model_metrics.values():\n",
    "    for metric in ['f1', 'recall', 'precision']:\n",
    "        mean_value = sum(model[metric]) / len(model[metric])\n",
    "        mean_min = min(mean_min, mean_value)\n",
    "        mean_max = max(mean_max, mean_value)\n",
    "\n",
    "# Helper function to apply color based on category-specific min-max value\n",
    "def color_cell(value, min_val, max_val):\n",
    "    if max_val == min_val:  # Handle case when all values are the same\n",
    "        normalized_value = 0.5  # Assign a neutral midpoint\n",
    "    else:\n",
    "        normalized_value = (value - min_val) / (max_val - min_val)\n",
    "    green_intensity = int(155 + 100 * normalized_value)\n",
    "    red_intensity = int(255 - 100 * normalized_value)\n",
    "    return f\"\\\\cellcolor[RGB]{{{red_intensity},{green_intensity},155}}{value:.1f}\"\n",
    "\n",
    "# Prepare the values to be inserted into the LaTeX table\n",
    "table_data = []\n",
    "metrics = ['F1', 'Recall', 'Precision']\n",
    "\n",
    "# Loop through the models and metrics to create rows\n",
    "for abbrev in folders.values():\n",
    "    for metric_idx, metric in enumerate(metrics):\n",
    "        row = [abbrev if metric_idx == 0 else \"\", metric]  # Add model name for the first metric row only\n",
    "        mean_value = 0  # Initialize mean value\n",
    "        metric_values = []\n",
    "\n",
    "        for i in range(len(model_metrics[abbrev][metric.lower()])):\n",
    "            value = float(model_metrics[abbrev][metric.lower()][i]) * 100\n",
    "            metric_values.append(value)\n",
    "            min_val, max_val = min_max_values[metric.lower()][i]\n",
    "            row.append(color_cell(value, min_val * 100, max_val * 100))  # Apply cell coloring\n",
    "\n",
    "        mean_value = sum(metric_values) / len(metric_values)  # Compute mean value\n",
    "        row.append(color_cell(mean_value, mean_min * 100, mean_max * 100))  # Apply cell coloring to the mean column\n",
    "        table_data.append(row)\n",
    "\n",
    "# Construct the LaTeX table with resizebox\n",
    "latex_table = \"\\\\begin{table}[htbp]\\n\\\\centering\\n\\\\resizebox{\\\\columnwidth}{!}{%\\n\\\\begin{tabular}{l|l|\" + \"|\".join([\"c\"] * (len(categories) + 1)) + \"}\\n\"\n",
    "latex_table += \"\\\\hline\\n\"\n",
    "latex_table += \"\\\\textbf{Model} & \\\\textbf{Metric} & \" + \" & \".join([f\"\\\\textbf{{{category}}}\" for category in categories]) + \" & \\\\textbf{Mean} \\\\\\\\\\n\"\n",
    "latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "# Add rows to the LaTeX table\n",
    "for row in table_data:\n",
    "    latex_table += f\"\\\\multirow{{3}}{{*}}{{{row[0]}}} & {row[1]} & \" if row[0] != \"\" else f\" & {row[1]} & \"\n",
    "    latex_table += \" & \".join(row[2:]) + \" \\\\\\\\\\n\"\n",
    "    if row[1] == \"Precision\":  # Add \\hline after the last row of each model\n",
    "        latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "latex_table += \"\\\\end{tabular}%\\n}\\n\"\n",
    "latex_table += \"\\\\caption{Three-category classification results with separate columns for models and metrics. F1, recall, precision, and their mean values are shown for No Pain, Mild Pain, and Pain categories.}\\n\"\n",
    "latex_table += \"\\\\label{tab:all_models_results}\\n\"\n",
    "latex_table += \"\\\\end{table}\"\n",
    "\n",
    "print(latex_table)"
   ],
   "id": "b6d40a89a9c6ad9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\resizebox{\\columnwidth}{!}{%\n",
      "\\begin{tabular}{l|l|c|c|c|c}\n",
      "\\hline\n",
      "\\textbf{Model} & \\textbf{Metric} & \\textbf{No Pain} & \\textbf{Mild} & \\textbf{Obvious} & \\textbf{Mean} \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{Full} & F1 & \\cellcolor[RGB]{155,255,155}93.1 & \\cellcolor[RGB]{155,255,155}51.2 & \\cellcolor[RGB]{156,253,155}54.3 & \\cellcolor[RGB]{161,248,155}66.2 \\\\\n",
      " & Recall & \\cellcolor[RGB]{155,255,155}92.9 & \\cellcolor[RGB]{224,185,155}52.5 & \\cellcolor[RGB]{155,255,155}51.0 & \\cellcolor[RGB]{163,246,155}65.4 \\\\\n",
      " & Precision & \\cellcolor[RGB]{237,172,155}93.4 & \\cellcolor[RGB]{155,255,155}50.0 & \\cellcolor[RGB]{158,251,155}58.1 & \\cellcolor[RGB]{158,251,155}67.2 \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{W/o graph rep.} & F1 & \\cellcolor[RGB]{178,231,155}87.7 & \\cellcolor[RGB]{178,231,155}46.4 & \\cellcolor[RGB]{155,255,155}55.2 & \\cellcolor[RGB]{170,239,155}63.1 \\\\\n",
      " & Recall & \\cellcolor[RGB]{188,221,155}80.8 & \\cellcolor[RGB]{155,255,155}73.4 & \\cellcolor[RGB]{155,255,155}51.0 & \\cellcolor[RGB]{155,255,155}68.4 \\\\\n",
      " & Precision & \\cellcolor[RGB]{155,255,155}95.9 & \\cellcolor[RGB]{208,201,155}33.9 & \\cellcolor[RGB]{155,255,155}60.2 & \\cellcolor[RGB]{170,239,155}63.4 \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{W/o GNN} & F1 & \\cellcolor[RGB]{184,225,155}86.4 & \\cellcolor[RGB]{255,155,155}30.7 & \\cellcolor[RGB]{255,155,155}4.0 & \\cellcolor[RGB]{239,170,155}40.3 \\\\\n",
      " & Recall & \\cellcolor[RGB]{190,219,155}79.9 & \\cellcolor[RGB]{255,155,155}43.2 & \\cellcolor[RGB]{255,155,155}10.2 & \\cellcolor[RGB]{227,182,155}44.4 \\\\\n",
      " & Precision & \\cellcolor[RGB]{218,191,155}93.9 & \\cellcolor[RGB]{242,167,155}23.8 & \\cellcolor[RGB]{255,155,155}2.5 & \\cellcolor[RGB]{240,169,155}40.1 \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{Only ResNet} & F1 & \\cellcolor[RGB]{255,155,155}70.3 & \\cellcolor[RGB]{253,156,155}31.0 & \\cellcolor[RGB]{254,155,155}4.2 & \\cellcolor[RGB]{255,155,155}35.2 \\\\\n",
      " & Recall & \\cellcolor[RGB]{255,155,155}56.5 & \\cellcolor[RGB]{171,238,155}68.3 & \\cellcolor[RGB]{242,167,155}15.3 & \\cellcolor[RGB]{220,189,155}46.7 \\\\\n",
      " & Precision & \\cellcolor[RGB]{255,155,155}92.8 & \\cellcolor[RGB]{255,155,155}20.1 & \\cellcolor[RGB]{254,155,155}2.5 & \\cellcolor[RGB]{245,164,155}38.5 \\\\\n",
      "\\hline\n",
      "\\end{tabular}%\n",
      "}\n",
      "\\caption{Three-category classification results with separate columns for models and metrics. F1, recall, precision, and their mean values are shown for No Pain, Mild Pain, and Pain categories.}\n",
      "\\label{tab:all_models_results}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1c65f1c339eb8105"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
