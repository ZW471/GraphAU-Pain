{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T22:37:44.506598Z",
     "start_time": "2025-01-05T22:37:43.379669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def process_multiple_inputs(input_file_output_folder_pairs):\n",
    "    \"\"\"\n",
    "    Processes multiple input file pairs, computes the classification report and confusion matrix,\n",
    "    and saves the outputs (confusion matrix image and classification report CSV) to the respective output folders.\n",
    "\n",
    "    Args:\n",
    "        input_file_output_folder_pairs (list of tuples): A list where each tuple contains:\n",
    "            - First element: List of two file paths [predictions_file, labels_file].\n",
    "            - Second element: Output folder path for saving results.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Define the column headers and label mapping\n",
    "    columns = ['Mild Pain', 'No Pain', 'Pain']\n",
    "    label_mapping = {0: 'No Pain', 1: 'Mild Pain', 2: 'Obvious Pain'}\n",
    "\n",
    "    for file_pair in input_file_output_folder_pairs:\n",
    "        # Unpack each tuple\n",
    "        input_files, output_folder = file_pair\n",
    "        predictions_file = input_files[0]\n",
    "        labels_file = input_files[1]\n",
    "\n",
    "        # Ensure the output folder exists\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Read and process labels\n",
    "        with open(labels_file, 'r') as lab:\n",
    "            labels = lab.readlines()\n",
    "            labels = [x.strip() for x in labels]\n",
    "            labels = [x.split(' ') for x in labels]\n",
    "            labels = pd.DataFrame(labels, columns=columns)\n",
    "            labels = labels.astype(int).idxmax(axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "        # Read and process predictions\n",
    "        with open(predictions_file, 'r') as pred:\n",
    "            predictions = pred.readlines()\n",
    "            predictions = [x.strip() for x in predictions]\n",
    "            predictions = [x.split(' ') for x in predictions]\n",
    "            predictions = pd.DataFrame(predictions, columns=columns)\n",
    "            predictions = predictions.astype(int).idxmax(axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "        # Generate and save classification report\n",
    "        report = classification_report(labels, predictions, target_names=label_mapping.values(), output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        report_csv_path = os.path.join(output_folder, 'classification_report.csv')\n",
    "        report_df.to_csv(report_csv_path)\n",
    "        print(f\"Classification report saved at: {report_csv_path}\")\n",
    "\n",
    "        # Generate and save confusion matrix\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        plt.figure(figsize=(7, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='viridis',\n",
    "                    xticklabels=label_mapping.values(), yticklabels=label_mapping.values(), annot_kws={\"size\": 14})\n",
    "        # Customizing visualization\n",
    "        plt.xlabel(\"Predicted\", fontsize=16, fontweight='bold')\n",
    "        plt.ylabel(\"Actual\", fontsize=16, fontweight='bold')\n",
    "        plt.xticks(fontsize=14)  # Set x-ticklabel font size\n",
    "        plt.yticks(fontsize=14)  # Set y-ticklabel font size\n",
    "        # No title\n",
    "        confusion_matrix_path = os.path.join(output_folder, 'confusion_matrix.png')\n",
    "        plt.savefig(confusion_matrix_path, bbox_inches='tight', pad_inches=0.1)\n",
    "        plt.close()  # Close the plot to avoid memory issues\n",
    "        print(f\"Confusion matrix saved at: {confusion_matrix_path}\")\n",
    "# Example list of input file pairs\n",
    "input_file_output_folder_pairs = [\n",
    "    (['pain_predictions_only_bb.txt', '../data/UNBC/list/UNBC_test_pspi_fold1.txt'], 'only backbone'),\n",
    "    (['pain_predictions_no_gnn.txt', '../data/UNBC/list/UNBC_test_pspi_fold1.txt'], 'no gnn'),\n",
    "    (['pain_predictions.txt', '../data/UNBC/list/UNBC_test_pspi_fold1.txt'], 'full'),\n",
    "    (['full gr.txt', '../data/UNBC/list/UNBC_test_pspi_fold1.txt'], 'full + graph representation'),\n",
    "    (['full gr no sft.txt', '../data/UNBC/list/UNBC_test_pspi_fold1.txt'], 'full no sft'),\n",
    "]\n",
    "\n",
    "# Call the function\n",
    "process_multiple_inputs(input_file_output_folder_pairs)"
   ],
   "id": "3cb6ea07d8c52456",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report saved at: only backbone\\classification_report.csv\n",
      "Confusion matrix saved at: only backbone\\confusion_matrix.png\n",
      "Classification report saved at: no gnn\\classification_report.csv\n",
      "Confusion matrix saved at: no gnn\\confusion_matrix.png\n",
      "Classification report saved at: full\\classification_report.csv\n",
      "Confusion matrix saved at: full\\confusion_matrix.png\n",
      "Classification report saved at: full + graph representation\\classification_report.csv\n",
      "Confusion matrix saved at: full + graph representation\\confusion_matrix.png\n",
      "Classification report saved at: full no sft\\classification_report.csv\n",
      "Confusion matrix saved at: full no sft\\confusion_matrix.png\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T23:37:07.266809Z",
     "start_time": "2025-01-05T23:37:07.240810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Folder names and abbreviated model names\n",
    "folders = {'full + graph representation': 'Full', 'full no sft': 'W/o SFT', 'full': 'W/o graph rep.', 'no gnn': 'W/o GNN','only backbone': 'Only ResNet' }\n",
    "categories = ['No Pain', 'Mild', 'Obvious']\n",
    "# Initialize an empty dictionary to store the metrics\n",
    "model_metrics = {}\n",
    "\n",
    "# Loop through each folder to extract required metrics (F1-score, recall, and precision)\n",
    "for folder, abbrev in folders.items():\n",
    "    report_path = os.path.join(folder, 'classification_report.csv')\n",
    "    if os.path.exists(report_path):\n",
    "        report = pd.read_csv(report_path, index_col=0)\n",
    "\n",
    "        # Get F1-scores, recall, and precision for each class\n",
    "        f1_scores = report.loc[['No Pain', 'Mild Pain', 'Obvious Pain'], 'f1-score'].values\n",
    "        recalls = report.loc[['No Pain', 'Mild Pain', 'Obvious Pain'], 'recall'].values\n",
    "        precisions = report.loc[['No Pain', 'Mild Pain', 'Obvious Pain'], 'precision'].values\n",
    "\n",
    "        # Save F1, recall, and precision for the current model\n",
    "        model_metrics[abbrev] = {'f1': f1_scores, 'recall': recalls, 'precision': precisions}\n",
    "\n",
    "# Calculate min and max for each category across all metrics\n",
    "min_max_values = {}\n",
    "for metric in ['f1', 'recall', 'precision']:\n",
    "    min_max_values[metric] = {i: (float('inf'), float('-inf')) for i in range(len(categories))}\n",
    "\n",
    "for model in model_metrics.values():\n",
    "    for metric in min_max_values.keys():\n",
    "        for i, value in enumerate(model[metric]):\n",
    "            current_min, current_max = min_max_values[metric][i]\n",
    "            min_max_values[metric][i] = (min(current_min, value), max(current_max, value))\n",
    "\n",
    "# Helper function to apply color based on category-specific min-max value\n",
    "def color_cell(value, min_val, max_val):\n",
    "    if max_val == min_val:  # Handle case when all values are the same\n",
    "        normalized_value = 0.5  # Assign a neutral midpoint\n",
    "    else:\n",
    "        normalized_value = (value - min_val) / (max_val - min_val)\n",
    "    green_intensity = int(155 + 100 * normalized_value)\n",
    "    red_intensity = int(255 - 100 * normalized_value)\n",
    "    return f\"\\\\cellcolor[RGB]{{{red_intensity},{green_intensity},155}}{value:.1f}\"\n",
    "\n",
    "# Prepare the values to be inserted into the LaTeX table\n",
    "table_data = []\n",
    "metrics = ['F1', 'Recall', 'Precision']\n",
    "\n",
    "# Loop through the models and metrics to create rows\n",
    "for abbrev in folders.values():\n",
    "    for metric_idx, metric in enumerate(metrics):\n",
    "        row = [abbrev if metric_idx == 0 else \"\", metric]  # Add model name for the first metric row only\n",
    "        for i in range(len(model_metrics[abbrev][metric.lower()])):\n",
    "            value = float(model_metrics[abbrev][metric.lower()][i]) * 100\n",
    "            min_val, max_val = min_max_values[metric.lower()][i]\n",
    "            row.append(color_cell(value, min_val * 100, max_val * 100))  # Apply cell coloring\n",
    "        table_data.append(row)\n",
    "\n",
    "# Construct the LaTeX table\n",
    "latex_table = \"\\\\begin{table}[htbp]\\n\\\\centering\\n\\\\begin{tabular}{l|l|\" + \"|\".join([\"c\"] * len(categories)) + \"}\\n\"\n",
    "latex_table += \"\\\\hline\\n\"\n",
    "latex_table += \"\\\\textbf{Model} & \\\\textbf{Metric} & \" + \" & \".join([f\"\\\\textbf{{{category}}}\" for category in categories]) + \" \\\\\\\\\\n\"\n",
    "latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "# Add rows to the LaTeX table\n",
    "for row in table_data:\n",
    "    latex_table += f\"\\\\multirow{{3}}{{*}}{{{row[0]}}} & {row[1]} & \" if row[0] != \"\" else f\" & {row[1]} & \"\n",
    "    latex_table += \" & \".join(row[2:]) + \" \\\\\\\\\\n\"\n",
    "    if row[1] == \"Precision\":  # Add \\hline after the last row of each model\n",
    "        latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "latex_table += \"\\\\end{tabular}\\n\"\n",
    "latex_table += \"\\\\caption{Three-category classification results with separate columns for models and metrics. F1, recall, and precision are shown for No Pain, Mild Pain, and Pain categories.}\\n\"\n",
    "latex_table += \"\\\\label{tab:all_models_results}\\n\"\n",
    "latex_table += \"\\\\end{table}\"\n",
    "\n",
    "print(latex_table)"
   ],
   "id": "b6d40a89a9c6ad9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\begin{tabular}{l|l|c|c|c}\n",
      "\\hline\n",
      "\\textbf{Model} & \\textbf{Metric} & \\textbf{No Pain} & \\textbf{Mild} & \\textbf{Obvious} \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{Full} & F1 & \\cellcolor[RGB]{155,255,155}93.1 & \\cellcolor[RGB]{155,255,155}51.2 & \\cellcolor[RGB]{165,244,155}54.3 \\\\\n",
      " & Recall & \\cellcolor[RGB]{155,255,155}92.9 & \\cellcolor[RGB]{184,225,155}52.5 & \\cellcolor[RGB]{185,224,155}51.0 \\\\\n",
      " & Precision & \\cellcolor[RGB]{192,217,155}93.4 & \\cellcolor[RGB]{155,255,155}50.0 & \\cellcolor[RGB]{166,243,155}58.1 \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{W/o SFT} & F1 & \\cellcolor[RGB]{164,245,155}90.1 & \\cellcolor[RGB]{163,246,155}47.3 & \\cellcolor[RGB]{155,255,155}60.4 \\\\\n",
      " & Recall & \\cellcolor[RGB]{170,239,155}86.1 & \\cellcolor[RGB]{169,240,155}63.3 & \\cellcolor[RGB]{176,233,155}56.1 \\\\\n",
      " & Precision & \\cellcolor[RGB]{173,236,155}94.6 & \\cellcolor[RGB]{183,226,155}37.8 & \\cellcolor[RGB]{155,255,155}65.5 \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{W/o graph rep.} & F1 & \\cellcolor[RGB]{173,236,155}87.7 & \\cellcolor[RGB]{165,244,155}46.4 & \\cellcolor[RGB]{163,246,155}55.2 \\\\\n",
      " & Recall & \\cellcolor[RGB]{182,227,155}80.8 & \\cellcolor[RGB]{155,255,155}73.4 & \\cellcolor[RGB]{185,224,155}51.0 \\\\\n",
      " & Precision & \\cellcolor[RGB]{155,255,155}95.9 & \\cellcolor[RGB]{191,218,155}33.9 & \\cellcolor[RGB]{163,246,155}60.2 \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{W/o GNN} & F1 & \\cellcolor[RGB]{180,229,155}85.7 & \\cellcolor[RGB]{226,183,155}17.6 & \\cellcolor[RGB]{239,170,155}9.6 \\\\\n",
      " & Recall & \\cellcolor[RGB]{187,222,155}78.6 & \\cellcolor[RGB]{232,177,155}18.7 & \\cellcolor[RGB]{155,255,155}68.4 \\\\\n",
      " & Precision & \\cellcolor[RGB]{181,228,155}94.1 & \\cellcolor[RGB]{231,178,155}16.6 & \\cellcolor[RGB]{247,162,155}5.2 \\\\\n",
      "\\hline\n",
      "\\multirow{3}{*}{Only ResNet} & F1 & \\cellcolor[RGB]{255,155,155}63.5 & \\cellcolor[RGB]{255,155,155}4.3 & \\cellcolor[RGB]{255,155,155}0.5 \\\\\n",
      " & Recall & \\cellcolor[RGB]{255,155,155}49.3 & \\cellcolor[RGB]{255,155,155}3.2 & \\cellcolor[RGB]{255,155,155}11.2 \\\\\n",
      " & Precision & \\cellcolor[RGB]{255,155,155}89.1 & \\cellcolor[RGB]{255,155,155}6.4 & \\cellcolor[RGB]{255,155,155}0.3 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\caption{Three-category classification results with separate columns for models and metrics. F1, recall, and precision are shown for No Pain, Mild Pain, and Pain categories.}\n",
      "\\label{tab:all_models_results}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1c65f1c339eb8105"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
